{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete. Ready to demonstrate data ingestion and normalization.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from io import StringIO, BytesIO\n",
        "\n",
        "# Add the parent directory to the system path to allow importing from dat-ingestion_bridge\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "# Explicitly import from the correct path\n",
        "from src.ingestion_utils import process_gym_data, IngestionMetadata\n",
        "\n",
        "# Create a temporary directory for test files\n",
        "if not os.path.exists(\"temp_data\"):\n",
        "    os.makedirs(\"temp_data\")\n",
        "\n",
        "print(\"Setup complete. Ready to demonstrate data ingestion and normalization.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Possible Data Formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\polri\\AppData\\Local\\Temp\\ipykernel_17372\\3453261950.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_excel_raw.loc[len(df_excel_raw)] = [None] * len(df_excel_raw.columns)\n"
          ]
        }
      ],
      "source": [
        "# Scenario 1: CSV with inconsistent delimiters and encoding issues\n",
        "csv_content_bad_delimiter = \"\"\"\n",
        "id;name;age;start_date\n",
        "1;Alice;30;2022-01-15\n",
        "2,Bob,24,16/03/2021\n",
        "3;Charlie;35;2020-11-01\n",
        "4,David,29,05-07-2023\n",
        "\"\"\"\n",
        "csv_path_bad_delimiter = \"temp_data/bad_delimiter_data.csv\"\n",
        "\n",
        "with open(csv_path_bad_delimiter, \"w\", encoding=\"latin1\") as f:\n",
        "    f.write(csv_content_bad_delimiter)\n",
        "\n",
        "\n",
        "# Scenario 2\n",
        "excel_path_junk_empty = \"temp_data/junk_empty_data.xlsx\"\n",
        "data_excel = {\n",
        "    'MemberID': ['M001', 'M002', 'M003', 'M004', 'M005', None, 'M007'],\n",
        "    'Name': ['Eve', 'Frank', 'Grace', None, 'Heidi', 'Ivy', 'Jack'],\n",
        "    'MembershipType': ['Gold', 'Silver', 'Gold', 'Bronze', 'Silver', 'Gold', 'Bronze'],\n",
        "    'LastVisit': ['2023-01-10', '15/02/2023', '2023-03-20', 'invalid-date', '2023-05-01', None, '2023-06-11'],\n",
        "    'Fee': [100.50, 75, 100.50, 50, 75, 100.50, 50],\n",
        "    'IsActive': ['YES', 'No', '1', '0', 'true', 'FALSE', None],\n",
        "    'Junk1': [None, None, None, None, None, None, None], # Empty column\n",
        "    'Junk2': ['garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage']\n",
        "}\n",
        "df_excel_raw = pd.DataFrame(data_excel)\n",
        "df_excel_raw.loc[len(df_excel_raw)] = [None] * len(df_excel_raw.columns)\n",
        "\n",
        "with pd.ExcelWriter(excel_path_junk_empty, engine='openpyxl') as writer:\n",
        "    df_excel_raw.to_excel(writer, index=False, sheet_name='Sheet1')\n",
        "\n",
        "\n",
        "# Scenario 3: TSV with long format and missing values\n",
        "tsv_content_long_missing = \"\"\"\n",
        "member_id\\tattribute\\tvalue\n",
        "101\\tgender\\tMale\n",
        "101\\tage\\t28\n",
        "102\\tgender\\tFemale\n",
        "102\\tage\\t34\n",
        "103\\tgender\\tNone\n",
        "103\\tage\\t30\n",
        "104\\tgender\\tMale\n",
        "104\\tage\\t\n",
        "105\\tgender\\tFemale\n",
        "105\\tage\\t22\n",
        "\"\"\"\n",
        "tsv_path_long_missing = \"temp_data/long_missing_data.tsv\"\n",
        "with open(tsv_path_long_missing, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(tsv_content_long_missing)\n",
        "\n",
        "\n",
        "# Scenario 4: CSV with mixed types, varying date formats, and partial corruption\n",
        "csv_content_mixed_corrupt = \"\"\"\n",
        "OrderID,Customer,OrderDate,Amount,Status,DeliveryDate\n",
        "1001,John Doe,2023-01-01,150.75,Completed,2023-01-05\n",
        "1002,Jane Smith,02/01/2023,abc,Pending,06/01/2023\n",
        "1003,Peter Jones,2023-Mar-03,200.00,Completed,2023-03-07\n",
        "1004,Alice Brown,04.04.2023,75.20,Cancelled,invalid-date\n",
        "1005,Bob White,2023/05/05,120,Completed,2023-May-09\n",
        "1006,Charlie Green,06-Jun-2023,300.00,Pending,10-Jun-2023\n",
        "1007,Diana Prince,07/Jul/2023,100,Completed,11/07/2023\n",
        "1008,Eve Black,invalid-date,50.00,Pending,2023-08-15\n",
        "\"\"\"\n",
        "csv_path_mixed_corrupt = \"temp_data/mixed_corrupt_data.csv\"\n",
        "with open(csv_path_mixed_corrupt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(csv_content_mixed_corrupt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scenario 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Processed DataFrame (Bad Delimiter) ---\n",
            "                      id     name   age  start_date\n",
            "0                      1    Alice  30.0  2022-01-15\n",
            "1    2,Bob,24,16/03/2021     <NA>  <NA>        <NA>\n",
            "2                      3  Charlie  35.0  2020-11-01\n",
            "3  4,David,29,05-07-2023     <NA>  <NA>        <NA>\n",
            "\n",
            "--- Metadata (Bad Delimiter) ---\n",
            "IngestionMetadata(file_type='csv', orientation='long', column_roles={'id': 'Categorical dimension', 'name': 'Categorical dimension', 'age': 'Categorical dimension', 'start_date': 'Categorical dimension'}, original_dtypes={'id': 'object', 'name': 'object', 'age': 'float64', 'start_date': 'object'}, inferred_dtypes={'id': 'string', 'name': 'string', 'age': 'string', 'start_date': 'string'}, warnings=[\"Failed to load with delimiter ',' and encoding 'utf-8': Expected 1 fields in line 4, saw 4\", \"Attempted to load with delimiter '\\t' and encoding 'utf-8', but resulted in a single column. Trying other options.\"])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\polri\\Desktop\\Projectes\\gym-member-retention-app\\src\\ingestion_utils.py:159: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
            "  datetime_series = pd.to_datetime(df_coerced[col], errors='coerce', dayfirst=True)\n"
          ]
        }
      ],
      "source": [
        "# Scenario 1: CSV with inconsistent delimiters and encoding issues\n",
        "\n",
        "df_processed, metadata = process_gym_data(csv_path_bad_delimiter)\n",
        "\n",
        "print(\"\\n--- Processed DataFrame (Bad Delimiter) ---\")\n",
        "print(df_processed.head())\n",
        "print(\"\\n--- Metadata (Bad Delimiter) ---\")\n",
        "print(metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scenario 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Processed DataFrame (Junk Columns/Empty Rows) ---\n",
            "  MemberID   Name MembershipType     LastVisit    Fee  IsActive    Junk2\n",
            "0     M001    Eve           Gold    2023-01-10  100.5      True  garbage\n",
            "1     M002  Frank         Silver    15/02/2023   75.0     False  garbage\n",
            "2     M003  Grace           Gold    2023-03-20  100.5      True  garbage\n",
            "3     M004   <NA>         Bronze  invalid-date   50.0     False  garbage\n",
            "4     M005  Heidi         Silver    2023-05-01   75.0      True  garbage\n",
            "5     <NA>    Ivy           Gold          <NA>  100.5     False  garbage\n",
            "6     M007   Jack         Bronze    2023-06-11   50.0      <NA>  garbage\n",
            "\n",
            "--- Metadata (Junk Columns/Empty Rows) ---\n",
            "IngestionMetadata(file_type='xlsx', orientation='long', column_roles={'MemberID': 'Categorical dimension', 'Name': 'Categorical dimension', 'MembershipType': 'Categorical dimension', 'LastVisit': 'Categorical dimension', 'Fee': 'Numeric metric', 'IsActive': 'Numeric metric', 'Junk2': 'Categorical dimension'}, original_dtypes={'MemberID': 'object', 'Name': 'object', 'MembershipType': 'object', 'LastVisit': 'object', 'Fee': 'float64', 'IsActive': 'object', 'Junk2': 'object'}, inferred_dtypes={'MemberID': 'string', 'Name': 'string', 'MembershipType': 'category', 'LastVisit': 'string', 'Fee': 'Float64', 'IsActive': 'boolean', 'Junk2': 'string'}, warnings=['Dropped 1 entirely empty columns.', \"Column 'IsActive' was coerced to boolean, but 14.29% of values were unparseable.\"])\n"
          ]
        }
      ],
      "source": [
        "# Scenario 2: Excel file with junk columns, empty rows, and mixed data types\n",
        "\n",
        "df_processed_excel, metadata_excel = process_gym_data(excel_path_junk_empty)\n",
        "\n",
        "print(\"\\n--- Processed DataFrame (Junk Columns/Empty Rows) ---\")\n",
        "print(df_processed_excel.head(8))\n",
        "print(\"\\n--- Metadata (Junk Columns/Empty Rows) ---\")\n",
        "print(metadata_excel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scenario 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Processed DataFrame (Long Format, Missing Values) ---\n",
            "   member_id attribute   value\n",
            "0        101    gender    Male\n",
            "1        101       age      28\n",
            "2        102    gender  Female\n",
            "3        102       age      34\n",
            "4        103    gender    <NA>\n",
            "5        103       age      30\n",
            "6        104    gender    Male\n",
            "7        104       age    <NA>\n",
            "\n",
            "--- Metadata (Long Format, Missing Values) ---\n",
            "IngestionMetadata(file_type='tsv', orientation='long', column_roles={'member_id': 'Numeric metric', 'attribute': 'Categorical dimension', 'value': 'Categorical dimension'}, original_dtypes={'member_id': 'int64', 'attribute': 'object', 'value': 'object'}, inferred_dtypes={'member_id': 'Int64', 'attribute': 'category', 'value': 'string'}, warnings=[\"Attempted to load with delimiter ',' and encoding 'utf-8', but resulted in a single column. Trying other options.\"])\n"
          ]
        }
      ],
      "source": [
        "# Scenario 3\n",
        "\n",
        "df_processed_tsv, metadata_tsv = process_gym_data(tsv_path_long_missing)\n",
        "\n",
        "print(\"\\n--- Processed DataFrame (Long Format, Missing Values) ---\")\n",
        "print(df_processed_tsv.head(8))\n",
        "print(\"\\n--- Metadata (Long Format, Missing Values) ---\")\n",
        "print(metadata_tsv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scenario 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Processed DataFrame (Mixed Types, Corrupt Data) ---\n",
            "   OrderID       Customer     OrderDate  Amount     Status  DeliveryDate\n",
            "0     1001       John Doe    2023-01-01  150.75  Completed    2023-01-05\n",
            "1     1002     Jane Smith    02/01/2023    <NA>    Pending    06/01/2023\n",
            "2     1003    Peter Jones   2023-Mar-03   200.0  Completed    2023-03-07\n",
            "3     1004    Alice Brown    04.04.2023    75.2  Cancelled  invalid-date\n",
            "4     1005      Bob White    2023/05/05   120.0  Completed   2023-May-09\n",
            "5     1006  Charlie Green   06-Jun-2023   300.0    Pending   10-Jun-2023\n",
            "6     1007   Diana Prince   07/Jul/2023   100.0  Completed    11/07/2023\n",
            "7     1008      Eve Black  invalid-date    50.0    Pending    2023-08-15\n",
            "\n",
            "--- Metadata (Mixed Types, Corrupt Data) ---\n",
            "IngestionMetadata(file_type='csv', orientation='long', column_roles={'OrderID': 'Numeric metric', 'Customer': 'Categorical dimension', 'OrderDate': 'Categorical dimension', 'Amount': 'Numeric metric', 'Status': 'Categorical dimension', 'DeliveryDate': 'Categorical dimension'}, original_dtypes={'OrderID': 'int64', 'Customer': 'object', 'OrderDate': 'object', 'Amount': 'object', 'Status': 'object', 'DeliveryDate': 'object'}, inferred_dtypes={'OrderID': 'Int64', 'Customer': 'string', 'OrderDate': 'string', 'Amount': 'Float64', 'Status': 'category', 'DeliveryDate': 'string'}, warnings=[\"Column 'Amount' was coerced to numeric, but 12.50% of values were unparseable.\"])\n"
          ]
        }
      ],
      "source": [
        "# Scenario 4\n",
        "\n",
        "df_processed_mixed, metadata_mixed = process_gym_data(csv_path_mixed_corrupt)\n",
        "\n",
        "print(\"\\n--- Processed DataFrame (Mixed Types, Corrupt Data) ---\")\n",
        "print(df_processed_mixed.head(8))\n",
        "print(\"\\n--- Metadata (Mixed Types, Corrupt Data) ---\")\n",
        "print(metadata_mixed)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
